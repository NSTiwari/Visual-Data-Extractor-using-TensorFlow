{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Visual_Data_Extractor_using_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzZ0iAH--6k6"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaUG3D6m_FEY"
      },
      "source": [
        "### **Clone and install the Tensorflow Object Detection API** \n",
        "\n",
        "In order to use the TensorFlow Object Detection API, we need to clone it's GitHub Repo.\n",
        "<br>\n",
        "\n",
        "#### **Dependencies**\n",
        "\n",
        "\n",
        "Most of the dependencies required come preloaded in Google Colab.  No extra installation is needed.\n",
        "<br>\n",
        "\n",
        "#### **Protocol Buffers**\n",
        "\n",
        "\n",
        "\n",
        "The TensorFlow Object Detection API relies on what are called `protocol buffers` (also known as `protobufs`). Protobufs are a language neutral way to describe information. That means you can write a protobuf once and then compile it to be used with other languages, like Python, Java or C [5].\n",
        "\n",
        "The `protoc` command used below is compiling all the protocol buffers in the `object_detection/protos` folder for Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbkuAjhU-3e6"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukzhAgID_gyP"
      },
      "source": [
        "%cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Uninstall and reinstall OpenCV\n",
        "This is required to make the notebook compatible with earlier version of TensorFlow."
      ],
      "metadata": {
        "id": "WGU76zc4VzAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall opencv-python-headless==4.5.5.62"
      ],
      "metadata": {
        "id": "r63WxYl2WCAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "id": "jiw7Qe11WDq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Restart Runtime.\n",
        "We need to restart runtime. Click on **Runtime** > click **Restart runtime**."
      ],
      "metadata": {
        "id": "6aRYNh2yeG-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Uninstall and reinstall TensorFlow 2.8\n",
        "Again, this is required to make the notebook compatible for model training. If this is not done, `DNN library is not found error` will arise."
      ],
      "metadata": {
        "id": "D-JG_kQnbArk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8"
      ],
      "metadata": {
        "id": "hp0_ucV9bDe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "id": "4ZrWMdF_bGVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkZtxPYCXLHu"
      },
      "source": [
        "Run the model builder test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzfZSmpSXMxS"
      },
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIj4L4S1neYu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOgMOdcmOzVc"
      },
      "source": [
        "### Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyNB-m_5O0kh"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTrBqJRKrfMh"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = '<your-kaggle-username>'\n",
        "os.environ['KAGGLE_KEY'] = '<your-kaggle-key>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBG_9zNwtBQd"
      },
      "source": [
        "%%bash\n",
        "mkdir /content/dataset\n",
        "cd /content/dataset\n",
        "kaggle datasets download -d nstiwari/graph-detection --unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrT-BLUHFIe5"
      },
      "source": [
        "##### Create a `labelmap.pbtxt` file in /content directory. Take the following as an example:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "item {\n",
        "  name: \"pie_chart\"\n",
        "  id: 1\n",
        "}\n",
        "\n",
        "item {\n",
        "  name: \"donut\"\n",
        "  id: 2\n",
        "}\n",
        "\n",
        "item {\n",
        "  name: \"bar_graph\"\n",
        "  id: 3\n",
        "}\n",
        "\n",
        "item {\n",
        "  name: \"line_chart\"\n",
        "  id: 4\n",
        "}\n",
        "\n",
        "item {\n",
        "  name: \"area_chart\"\n",
        "  id: 5\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zff5msFLAm8g"
      },
      "source": [
        "##### Converting data to TFRecord\n",
        "The dataset contains two files `train_labels.csv` and `test_labels.csv` which need to be converted into TFRecord format so that it can be fed into Tensorflowâ€™s 2 Object Detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yIkwN0MCbAR"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VqGdNpF7kwU"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/NSTiwari/Visual-Data-Extractor-using-TensorFlow/master/generate_tf_records.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/NSTiwari/Visual-Data-Extractor-using-TensorFlow/master/xml_to_csv.py -P /content/dataset/graph-detection/"
      ],
      "metadata": {
        "id": "dgyvnWamxYAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!python dataset/graph-detection/xml_to_csv.py"
      ],
      "metadata": {
        "id": "rPzQQwwqx99H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRYscfzGEgl3"
      },
      "source": [
        "!python generate_tf_records.py -l labelmap.pbtxt -o dataset/train.record -i dataset/graph-detection/images -csv dataset/graph-detection/train_labels.csv\n",
        "!python generate_tf_records.py -l labelmap.pbtxt -o dataset/test.record -i dataset/graph-detection/images -csv dataset/graph-detection/val_labels.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwpHRbZUngms"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mzXmPHfPJsP"
      },
      "source": [
        "### Configuring train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5vys2yVG7_m"
      },
      "source": [
        "We are going to use the pretrained TF2 MobileNet V2 model as the feature extractor in the SSD MobileNet V2 Object Detection model. So the next logical step is to download and untar the pretrained TF2 MobileNet V2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE5PyJUpP7F8"
      },
      "source": [
        "#### Downloading MobileNet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qafiqrBJG8pF"
      },
      "source": [
        "%cd /content\n",
        "!wget http://download.tensorflow.org/models/object_detection/classification/tf2/20200710/mobilenet_v2.tar.gz\n",
        "!tar -xvf mobilenet_v2.tar.gz\n",
        "!rm mobilenet_v2.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zRvdLDfRGA_"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
        "!mv ssd_mobilenet_v2_320x320_coco17_tpu-8.config mobilenet_v2.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5gIl9aSVdGq"
      },
      "source": [
        "#### Defining training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVps_k4JRGa7"
      },
      "source": [
        "num_classes = 5\n",
        "batch_size = 24 #16\n",
        "num_steps = 7500 #1500\n",
        "num_eval_steps = 1000\n",
        "\n",
        "train_record_path = '/content/dataset/train.record'\n",
        "test_record_path = '/content/dataset/test.record'\n",
        "model_dir = '/content/training/'\n",
        "labelmap_path = '/content/labelmap.pbtxt'\n",
        "\n",
        "pipeline_config_path = 'mobilenet_v2.config'\n",
        "fine_tune_checkpoint = '/content/mobilenet_v2/mobilenet_v2.ckpt-1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOiWE_mCVgap"
      },
      "source": [
        "#### Editing config file\n",
        "\n",
        "The next cell is modification of the code available at [4]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH9pVN4qfbAb"
      },
      "source": [
        "import re\n",
        "\n",
        "with open(pipeline_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open(pipeline_config_path, 'w') as f:\n",
        "\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "  'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "  \n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint),\n",
        "                  config)\n",
        "  \n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "  \n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "  \n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(num_classes), config)\n",
        "  \n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "  \n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "  \n",
        "  f.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_FmiIbinigI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHxMKaxfhGyU"
      },
      "source": [
        "### Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dx_wEykfpuv"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R_znCjFXdhj"
      },
      "source": [
        "### Export the Inference Graph\n",
        "\n",
        "The below code cell adds a line to the tf_utils.py file. This is a temporary fix to a exporting issue occuring when using the OD API with Tensorflow 2. This code will be removed as soon as the OD Team puts out a fix.\n",
        "\n",
        "All credit goes to the Github users [Jacobsolawetz](https://github.com/Jacobsolawetz) and [ Tanner Gilbert](https://github.com/TannerGilbert), who provided this [temporary fix](https://github.com/tensorflow/models/issues/8841#issuecomment-657647648)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsrZNbomXfzA"
      },
      "source": [
        "with open('/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py') as f:\n",
        "    tf_utils = f.read()\n",
        "\n",
        "with open('/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py', 'w') as f:\n",
        "  # Set labelmap path\n",
        "  throw_statement = \"raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\"\n",
        "  tf_utils = tf_utils.replace(throw_statement, \"if not isinstance(x, str):\" + throw_statement)\n",
        "  f.write(tf_utils)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRJxDZ36XdKw"
      },
      "source": [
        "output_directory = 'inference_graph'\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {model_dir} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_config_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ4nCG2QaUrk"
      },
      "source": [
        "##### Downloading weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqgiuAVsHFIK"
      },
      "source": [
        "!zip -r /content/saved_model.zip /content/inference_graph/saved_model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ecN2ZoXaWJp"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/saved_model.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}